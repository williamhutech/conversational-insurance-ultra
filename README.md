# Conversational Insurance Ultra

> AI-powered conversational insurance platform transforming how customers discover, compare, and purchase travel insurance through natural language conversations on Claude/ChatGPT.

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.108+-green.svg)](https://fastapi.tiangolo.com/)
[![FastMCP](https://img.shields.io/badge/FastMCP-0.1+-orange.svg)](https://github.com/jlowin/fastmcp)

---

## What We're Building

An AI-powered conversational insurance platform with **5 Revolutionary Blocks**:

### ğŸ§  Block 1: Policy Intelligence Engine
- Dual-layer intelligence: Normalized taxonomy + Original policy text
- Multi-database architecture (Postgres + Neo4j + Vector DB)
- Apples-to-apples policy comparisons
- 16+ language support with standardized terminology

### ğŸ’¬ Block 2: Conversational FAQ & Recommendations
- Natural language Q&A with intelligent data source switching
- Context-aware conversations with Mem0 memory
- Handles complex multi-turn discussions
- Preserves customer preferences across sessions

### ğŸ“„ Block 3: Document Intelligence & Auto-Quotation
**Game Changer:** Upload flight bookings instead of filling forms
- OCR + AI extraction from travel documents
- Automatic data extraction: dates, destinations, travelers, trip value
- Cross-document validation
- Instant personalized quotations
- **Reduces quote time from 20 minutes â†’ 2 minutes**

### ğŸ’³ Block 4: Seamless Purchase Execution
- Complete purchase within conversation
- Stripe payment integration
- Automatic policy generation and delivery
- Full conversation continuity

### ğŸ“Š Block 5: Data-Driven Recommendations
**MSIG's Competitive Moat:** Leverage proprietary claims data
- Evidence-based coverage suggestions
- Destination risk analysis from actual claims
- Demographic-specific recommendations
- Insights competitors can't match

---

## Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Claude / ChatGPT                         â”‚
â”‚                  (User Interface Layer)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ MCP Protocol
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  FastMCP Server                             â”‚
â”‚             (12 Conversational Tools)                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Block 1  â”‚ Block 2  â”‚ Block 3  â”‚ Block 4  â”‚ Block 5  â”‚  â”‚
â”‚  â”‚ Policy   â”‚   FAQ    â”‚ Document â”‚ Purchase â”‚Analytics â”‚  â”‚
â”‚  â”‚ Intel    â”‚  & QA    â”‚   OCR    â”‚ Payment  â”‚ Recom.   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ HTTP/REST
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  FastAPI Backend                            â”‚
â”‚              (Business Logic Layer)                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ API Routers â”‚  Services   â”‚    Models    â”‚Dependenciesâ”‚ â”‚
â”‚  â”‚   (5 files) â”‚ (13 files)  â”‚  (5 files)   â”‚           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼            â–¼            â–¼            â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚Supabaseâ”‚  â”‚ Neo4j  â”‚  â”‚  Mem0   â”‚  â”‚ Stripe â”‚
   â”‚Postgresâ”‚  â”‚ Graph  â”‚  â”‚Customer â”‚  â”‚Payment â”‚
   â”‚+Vector â”‚  â”‚   DB   â”‚  â”‚ Memory  â”‚  â”‚        â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Tech Stack

### Core Framework
- **FastAPI** - High-performance async API framework
- **FastMCP** - Model Context Protocol server for Claude/ChatGPT integration
- **Python 3.11+** - Modern Python with type hints

### Databases
- **Supabase** - Postgres + pgvector for normalized policies and embeddings
- **Neo4j** - Graph database for policy relationships and claims analysis
- **Mem0** - Customer conversation memory and context management

### Document Processing
- **Tesseract OCR** - Open-source text extraction
- **EasyOCR** - Deep learning-based OCR
- **PyPDF** - PDF parsing and manipulation

### AI & ML
- **Anthropic Claude** - Primary LLM for conversations and analysis
- **OpenAI** - Embeddings for semantic search

### Payments
- **Stripe** - Payment processing and subscription management

---

## Project Structure

```
conversational-insurance-ultra/
â”œâ”€â”€ mcp-server/                    # ğŸ¯ FastMCP Server
â”‚   â”œâ”€â”€ server.py                  # Main MCP entry point (12 tools)
â”‚   â”œâ”€â”€ tools/                     # Individual MCP tool implementations
â”‚   â”œâ”€â”€ prompts/                   # Prompt templates
â”‚   â””â”€â”€ client/                    # Backend API client
â”‚       â””â”€â”€ backend_client.py
â”‚
â”œâ”€â”€ backend/                       # ğŸ”§ FastAPI Backend
â”‚   â”œâ”€â”€ main.py                    # FastAPI application
â”‚   â”œâ”€â”€ config.py                  # Pydantic settings
â”‚   â”œâ”€â”€ dependencies.py            # Dependency injection
â”‚   â”œâ”€â”€ api/                       # REST API routers (5 routers)
â”‚   â”‚   â”œâ”€â”€ policies.py            # Block 1: Policy Intelligence
â”‚   â”‚   â”œâ”€â”€ documents.py           # Block 3: Document upload
â”‚   â”‚   â”œâ”€â”€ quotations.py          # Block 3: Quote generation
â”‚   â”‚   â”œâ”€â”€ purchases.py           # Block 4: Payment flow
â”‚   â”‚   â””â”€â”€ analytics.py           # Block 5: Recommendations
â”‚   â”‚
â”‚   â”œâ”€â”€ services/                  # Business logic (13 services)
â”‚   â”‚   â”œâ”€â”€ policy_ingestion.py
â”‚   â”‚   â”œâ”€â”€ policy_normalization.py
â”‚   â”‚   â”œâ”€â”€ policy_comparison.py
â”‚   â”‚   â”œâ”€â”€ vector_search.py
â”‚   â”‚   â”œâ”€â”€ qa_engine.py
â”‚   â”‚   â”œâ”€â”€ document_processor.py
â”‚   â”‚   â”œâ”€â”€ travel_data_extractor.py
â”‚   â”‚   â”œâ”€â”€ quotation_generator.py
â”‚   â”‚   â”œâ”€â”€ purchase_service.py
â”‚   â”‚   â”œâ”€â”€ stripe_integration.py
â”‚   â”‚   â”œâ”€â”€ policy_generator.py
â”‚   â”‚   â”œâ”€â”€ claims_analyzer.py
â”‚   â”‚   â””â”€â”€ recommendation_engine.py
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                    # Pydantic models (5 models)
â”‚   â”‚   â”œâ”€â”€ policy.py
â”‚   â”‚   â”œâ”€â”€ document.py
â”‚   â”‚   â”œâ”€â”€ quotation.py
â”‚   â”‚   â”œâ”€â”€ purchase.py
â”‚   â”‚   â””â”€â”€ claim.py
â”‚   â”‚
â”‚   â””â”€â”€ database/                  # Database clients (4 clients)
â”‚       â”œâ”€â”€ postgres_client.py     # Supabase Postgres
â”‚       â”œâ”€â”€ neo4j_client.py        # Neo4j graph DB
â”‚       â”œâ”€â”€ vector_client.py       # pgvector search
â”‚       â””â”€â”€ mem0_client.py         # Mem0 memory
â”‚
â”œâ”€â”€ libs/                          # ğŸ“š Shared Libraries
â”‚   â”œâ”€â”€ ocr/                       # OCR implementations
â”‚   â”‚   â”œâ”€â”€ tesseract_ocr.py
â”‚   â”‚   â”œâ”€â”€ easyocr_client.py
â”‚   â”‚   â””â”€â”€ ocr_router.py
â”‚   â”œâ”€â”€ storage/
â”‚   â”‚   â””â”€â”€ supabase_storage.py    # Document storage
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ logging.py
â”‚       â””â”€â”€ validation.py
â”‚
â”œâ”€â”€ database/                      # ğŸ—„ï¸ Database Setup & Data
â”‚   â”œâ”€â”€ postgres/
â”‚   â”‚   â”œâ”€â”€ schema.sql             # Table definitions
â”‚   â”‚   â””â”€â”€ seed_policies.py       # Load taxonomy JSON
â”‚   â”œâ”€â”€ neo4j/
â”‚   â”‚   â”œâ”€â”€ schema.cypher          # Graph schema
â”‚   â”‚   â”œâ”€â”€ seed_graph.py          # Load claims data
â”‚   â”‚   â””â”€â”€ claims/                # Claims data PDFs
â”‚   â”œâ”€â”€ vector/
â”‚   â”‚   â””â”€â”€ init_embeddings.py     # Generate embeddings
â”‚   â”œâ”€â”€ policy_wordings/           # Source policy PDFs
â”‚   â””â”€â”€ supabase/taxonomy/         # Taxonomy JSON + docs
â”‚
â”œâ”€â”€ .env.example                   # Environment template
â”œâ”€â”€ pyproject.toml                 # Project dependencies
â”œâ”€â”€ requirements.txt               # Frozen dependencies
â”œâ”€â”€ docker-compose.yml             # Local development services
â””â”€â”€ README.md                      # This file
```

---

## Getting Started

### Prerequisites

- **Python 3.11+** installed
- **UV** package manager (recommended) or pip
- **Accounts & API Keys:**
  - Supabase account (database + storage)
  - Neo4j Aura account (or local Neo4j)
  - Mem0 API key
  - Anthropic API key (Claude)
  - Stripe account (test mode)

### Installation

1. **Clone the repository:**
   ```bash
   git clone https://github.com/williamhutech/conversational-insurance-ultra.git
   cd conversational-insurance-ultra
   ```

2. **Create and activate virtual environment:**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies:**
   ```bash
   # Using UV (recommended)
   uv pip install -e .

   # Or using pip
   pip install -e .
   ```

4. **Configure environment:**
   ```bash
   cp .env.example .env
   # Edit .env with your API keys and database credentials
   ```

5. **Set up databases:**
   ```bash
   # Start local services (optional)
   docker-compose up -d neo4j redis

   # Initialize database schemas
   python -m database.postgres.seed_policies
   python -m database.neo4j.seed_graph
   python -m database.vector.init_embeddings
   ```

### Running the Application

**1. Start the FastAPI Backend:**
```bash
uvicorn backend.main:app --reload
```
Backend will be available at `http://localhost:8000`

**2. Start the MCP Server:**
```bash
python -m mcp-server.server
```

**3. Configure Claude Desktop / ChatGPT:**

Add to Claude Desktop config (`~/Library/Application Support/Claude/claude_desktop_config.json`):
```json
{
  "mcpServers": {
    "insurance-ultra": {
      "command": "python",
      "args": ["-m", "mcp-server.server"],
      "cwd": "/path/to/conversational-insurance-ultra"
    }
  }
}
```

**4. Start Conversing!**
Open Claude Desktop and start asking about travel insurance!

---

## API Documentation

Once the backend is running, visit:
- **Swagger UI:** `http://localhost:8000/docs`
- **ReDoc:** `http://localhost:8000/redoc`

---

## Development

### Project Status

**Current Phase:** Architecture Setup (v0.1.0)

This repository contains the complete architecture scaffolding with:
- âœ… Directory structure
- âœ… Configuration management
- âœ… Database client interfaces
- âœ… Pydantic models
- âœ… FastAPI application skeleton
- âœ… FastMCP server skeleton
- â³ Business logic implementations (TODO)
- â³ API endpoint implementations (TODO)
- â³ Service layer implementations (TODO)

### Next Steps

1. **Implement Database Schemas**
   - Create Postgres tables for policies, quotations, purchases
   - Define Neo4j graph schema for policy relationships
   - Set up pgvector tables for embeddings

2. **Implement Core Services**
   - Policy comparison logic
   - OCR and data extraction
   - Quotation calculation engine
   - Stripe payment integration

3. **Implement MCP Tools**
   - Connect MCP tools to backend API
   - Add error handling and retries
   - Implement streaming responses

4. **Load Data**
   - Parse and load Taxonomy_Hackathon.json
   - Extract data from policy PDFs
   - Generate embeddings for vector search
   - Load claims data into Neo4j

### Running Tests

```bash
# Install dev dependencies
uv pip install -e ".[dev]"

# Run tests
pytest

# Run with coverage
pytest --cov=backend --cov=mcp-server
```

### Code Quality

```bash
# Format code
black .

# Lint code
ruff check .

# Type check
mypy backend/ mcp-server/
```

---

## Environment Variables

See `.env.example` for all required environment variables.

Key variables:
- `SUPABASE_URL`, `SUPABASE_KEY` - Supabase connection
- `NEO4J_URI`, `NEO4J_PASSWORD` - Neo4j connection
- `MEM0_API_KEY` - Mem0 customer memory
- `ANTHROPIC_API_KEY` - Claude API
- `STRIPE_SECRET_KEY` - Stripe payments

---

## Contributing

This is currently a private project for MSIG hackathon. Contribution guidelines will be added if open-sourced.

---

## License

Proprietary - MSIG Insurance

---

## Contact

**Project Lead:** William Hu
**Organization:** MSIG Insurance
**Repository:** https://github.com/williamhutech/conversational-insurance-ultra

---

## Acknowledgments

- **FastMCP** by Jlowin for MCP server framework
- **FastAPI** by Tiangolo for the amazing web framework
- **Anthropic** for Claude AI capabilities
- **MSIG Insurance** for claims data and domain expertise
